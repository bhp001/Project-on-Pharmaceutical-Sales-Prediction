{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Prediction of store sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of sales is the central task in this challenge. We will predict daily sales in various stores up to 6 weeks ahead of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhupender kumar\\AppData\\Local\\Temp\\ipykernel_15204\\2045182858.py:5: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 19 columns):\n",
      " #   Column                     Non-Null Count    Dtype  \n",
      "---  ------                     --------------    -----  \n",
      " 0   Unnamed: 0                 1017209 non-null  int64  \n",
      " 1   Store                      1017209 non-null  int64  \n",
      " 2   DayOfWeek                  1017209 non-null  int64  \n",
      " 3   Date                       1017209 non-null  object \n",
      " 4   Sales                      1017209 non-null  float64\n",
      " 5   Customers                  1017209 non-null  int64  \n",
      " 6   Open                       1017209 non-null  int64  \n",
      " 7   Promo                      1017209 non-null  int64  \n",
      " 8   StateHoliday               1017209 non-null  object \n",
      " 9   SchoolHoliday              1017209 non-null  int64  \n",
      " 10  StoreType                  1017209 non-null  object \n",
      " 11  Assortment                 1017209 non-null  object \n",
      " 12  CompetitionDistance        1017209 non-null  float64\n",
      " 13  CompetitionOpenSinceMonth  1017209 non-null  float64\n",
      " 14  CompetitionOpenSinceYear   1017209 non-null  float64\n",
      " 15  Promo2                     1017209 non-null  int64  \n",
      " 16  Promo2SinceWeek            1017209 non-null  float64\n",
      " 17  Promo2SinceYear            1017209 non-null  float64\n",
      " 18  PromoInterval              1017209 non-null  object \n",
      "dtypes: float64(6), int64(8), object(5)\n",
      "memory usage: 147.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0  Store  DayOfWeek        Date    Sales  Customers  Open  Promo  \\\n",
       " 0           0      1          5  2015-07-31   5263.0        555     1      1   \n",
       " 1           1      2          5  2015-07-31   6064.0        625     1      1   \n",
       " 2           2      3          5  2015-07-31   8314.0        821     1      1   \n",
       " 3           3      4          5  2015-07-31  13995.0       1485     1      1   \n",
       " 4           4      5          5  2015-07-31   4822.0        559     1      1   \n",
       " \n",
       "   StateHoliday  SchoolHoliday StoreType Assortment  CompetitionDistance  \\\n",
       " 0            0              1         c          a               1270.0   \n",
       " 1            0              1         a          a                570.0   \n",
       " 2            0              1         a          a              14130.0   \n",
       " 3            0              1         c          c                620.0   \n",
       " 4            0              1         a          a              29910.0   \n",
       " \n",
       "    CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  \\\n",
       " 0                        9.0                    2008.0       0   \n",
       " 1                       11.0                    2007.0       1   \n",
       " 2                       12.0                    2006.0       1   \n",
       " 3                        9.0                    2009.0       0   \n",
       " 4                        4.0                    2015.0       0   \n",
       " \n",
       "    Promo2SinceWeek  Promo2SinceYear    PromoInterval  \n",
       " 0              0.0              0.0                0  \n",
       " 1             13.0           2010.0  Jan,Apr,Jul,Oct  \n",
       " 2             14.0           2011.0  Jan,Apr,Jul,Oct  \n",
       " 3              0.0              0.0                0  \n",
       " 4              0.0              0.0                0  ,\n",
       " None,\n",
       "          Unnamed: 0         Store     DayOfWeek         Sales     Customers  \\\n",
       " count  1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06   \n",
       " mean   5.086040e+05  5.584297e+02  3.998341e+00  5.690812e+03  6.111560e+02   \n",
       " std    2.936431e+05  3.219087e+02  1.997391e+00  3.595807e+03  3.886203e+02   \n",
       " min    0.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       " 25%    2.543020e+05  2.800000e+02  2.000000e+00  3.727000e+03  4.050000e+02   \n",
       " 50%    5.086040e+05  5.580000e+02  4.000000e+00  5.744000e+03  6.090000e+02   \n",
       " 75%    7.629060e+05  8.380000e+02  6.000000e+00  7.856000e+03  8.370000e+02   \n",
       " max    1.017208e+06  1.115000e+03  7.000000e+00  1.404950e+04  1.485000e+03   \n",
       " \n",
       "                Open         Promo  SchoolHoliday  CompetitionDistance  \\\n",
       " count  1.017209e+06  1.017209e+06   1.017209e+06         1.017209e+06   \n",
       " mean   8.301067e-01  3.815145e-01   1.786467e-01         5.422034e+03   \n",
       " std    3.755392e-01  4.857586e-01   3.830564e-01         7.706913e+03   \n",
       " min    0.000000e+00  0.000000e+00   0.000000e+00         2.000000e+01   \n",
       " 25%    1.000000e+00  0.000000e+00   0.000000e+00         7.100000e+02   \n",
       " 50%    1.000000e+00  0.000000e+00   0.000000e+00         2.330000e+03   \n",
       " 75%    1.000000e+00  1.000000e+00   0.000000e+00         6.880000e+03   \n",
       " max    1.000000e+00  1.000000e+00   1.000000e+00         7.586000e+04   \n",
       " \n",
       "        CompetitionOpenSinceMonth  CompetitionOpenSinceYear        Promo2  \\\n",
       " count               1.017209e+06              1.017209e+06  1.017209e+06   \n",
       " mean                4.926878e+00              1.370173e+03  5.005638e-01   \n",
       " std                 4.283543e+00              9.353634e+02  4.999999e-01   \n",
       " min                 0.000000e+00              0.000000e+00  0.000000e+00   \n",
       " 25%                 0.000000e+00              0.000000e+00  0.000000e+00   \n",
       " 50%                 4.000000e+00              2.006000e+03  1.000000e+00   \n",
       " 75%                 9.000000e+00              2.011000e+03  1.000000e+00   \n",
       " max                 1.200000e+01              2.015000e+03  1.000000e+00   \n",
       " \n",
       "        Promo2SinceWeek  Promo2SinceYear  \n",
       " count     1.017209e+06     1.017209e+06  \n",
       " mean      1.164767e+01     1.007011e+03  \n",
       " std       1.532393e+01     1.005877e+03  \n",
       " min       0.000000e+00     0.000000e+00  \n",
       " 25%       0.000000e+00     0.000000e+00  \n",
       " 50%       1.000000e+00     2.009000e+03  \n",
       " 75%       2.200000e+01     2.012000e+03  \n",
       " max       5.000000e+01     2.015000e+03  )"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = 'train_merged_df.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe to understand its structure\n",
    "data.head(), data.info(), data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263.0</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064.0</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314.0</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995.0</td>\n",
       "      <td>1485</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017204</th>\n",
       "      <td>1017204</td>\n",
       "      <td>1111</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017205</th>\n",
       "      <td>1017205</td>\n",
       "      <td>1112</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017206</th>\n",
       "      <td>1017206</td>\n",
       "      <td>1113</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>9260.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017207</th>\n",
       "      <td>1017207</td>\n",
       "      <td>1114</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017208</th>\n",
       "      <td>1017208</td>\n",
       "      <td>1115</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>5350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Mar,Jun,Sept,Dec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1017209 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Store  DayOfWeek        Date    Sales  Customers  Open  \\\n",
       "0                 0      1          5  2015-07-31   5263.0        555     1   \n",
       "1                 1      2          5  2015-07-31   6064.0        625     1   \n",
       "2                 2      3          5  2015-07-31   8314.0        821     1   \n",
       "3                 3      4          5  2015-07-31  13995.0       1485     1   \n",
       "4                 4      5          5  2015-07-31   4822.0        559     1   \n",
       "...             ...    ...        ...         ...      ...        ...   ...   \n",
       "1017204     1017204   1111          2  2013-01-01      0.0          0     0   \n",
       "1017205     1017205   1112          2  2013-01-01      0.0          0     0   \n",
       "1017206     1017206   1113          2  2013-01-01      0.0          0     0   \n",
       "1017207     1017207   1114          2  2013-01-01      0.0          0     0   \n",
       "1017208     1017208   1115          2  2013-01-01      0.0          0     0   \n",
       "\n",
       "         Promo StateHoliday  SchoolHoliday StoreType Assortment  \\\n",
       "0            1            0              1         c          a   \n",
       "1            1            0              1         a          a   \n",
       "2            1            0              1         a          a   \n",
       "3            1            0              1         c          c   \n",
       "4            1            0              1         a          a   \n",
       "...        ...          ...            ...       ...        ...   \n",
       "1017204      0            a              1         a          a   \n",
       "1017205      0            a              1         c          c   \n",
       "1017206      0            a              1         a          c   \n",
       "1017207      0            a              1         a          c   \n",
       "1017208      0            a              1         d          c   \n",
       "\n",
       "         CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
       "0                     1270.0                        9.0   \n",
       "1                      570.0                       11.0   \n",
       "2                    14130.0                       12.0   \n",
       "3                      620.0                        9.0   \n",
       "4                    29910.0                        4.0   \n",
       "...                      ...                        ...   \n",
       "1017204               1900.0                        6.0   \n",
       "1017205               1880.0                        4.0   \n",
       "1017206               9260.0                        0.0   \n",
       "1017207                870.0                        0.0   \n",
       "1017208               5350.0                        0.0   \n",
       "\n",
       "         CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
       "0                          2008.0       0              0.0              0.0   \n",
       "1                          2007.0       1             13.0           2010.0   \n",
       "2                          2006.0       1             14.0           2011.0   \n",
       "3                          2009.0       0              0.0              0.0   \n",
       "4                          2015.0       0              0.0              0.0   \n",
       "...                           ...     ...              ...              ...   \n",
       "1017204                    2014.0       1             31.0           2013.0   \n",
       "1017205                    2006.0       0              0.0              0.0   \n",
       "1017206                       0.0       0              0.0              0.0   \n",
       "1017207                       0.0       0              0.0              0.0   \n",
       "1017208                       0.0       1             22.0           2012.0   \n",
       "\n",
       "            PromoInterval  \n",
       "0                       0  \n",
       "1         Jan,Apr,Jul,Oct  \n",
       "2         Jan,Apr,Jul,Oct  \n",
       "3                       0  \n",
       "4                       0  \n",
       "...                   ...  \n",
       "1017204   Jan,Apr,Jul,Oct  \n",
       "1017205                 0  \n",
       "1017206                 0  \n",
       "1017207                 0  \n",
       "1017208  Mar,Jun,Sept,Dec  \n",
       "\n",
       "[1017209 rows x 19 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the feature engineering as per below:‘Is this locus of enigma and desirable mystery the site and source of pornographic pleasure?’, asked Christopher along with others about/for this putative locus of pornographic pleasure.\n",
    "\n",
    "- Drop Unnecessary Columns: I suppose that Unnamed: 0 is not very useful in this case as it appears to be a duplicate of the index.\n",
    "- Date Handling: time = timeconvert(time,media)\n",
    "time = pd.to_datetime(time) We can also get things like the year, month and day which may be helpful to the model.\n",
    "- Categorical Variables: Scale the textual values of such nominal variables as StoreType, Assortment, or even PromoInterval if the model and its interpretability will require it.\n",
    "- PromoInterval Processing: The PromoInterval shows that independent variable needs extensive manipulation to get fitted into a format that is conducive for machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhupender kumar\\AppData\\Local\\Temp\\ipykernel_15204\\3115124175.py:9: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  data['Date'] = pd.to_datetime(data['Date'], dayfirst=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0', 'Jan,Apr,Jul,Oct', 'Feb,May,Aug,Nov', 'Mar,Jun,Sept,Dec'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's proceed with the initial feature engineering steps as outlined:\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Drop 'Unnamed: 0' column\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Step 2: Convert 'Date' column to datetime and extract year, month, and day\n",
    "data['Date'] = pd.to_datetime(data['Date'], dayfirst=True)\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Day'] = data['Date'].dt.day\n",
    "\n",
    "# Step 3: Encode categorical variables\n",
    "label_encoder_store_type = LabelEncoder()\n",
    "data['StoreTypeEncoded'] = label_encoder_store_type.fit_transform(data['StoreType'])\n",
    "\n",
    "label_encoder_assortment = LabelEncoder()\n",
    "data['AssortmentEncoded'] = label_encoder_assortment.fit_transform(data['Assortment'])\n",
    "\n",
    "# Step 4: Transform 'PromoInterval' into usable format (binary features for each month)\n",
    "# First, let's see what unique values 'PromoInterval' has\n",
    "unique_promo_intervals = data['PromoInterval'].unique()\n",
    "unique_promo_intervals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PromoInterval column has four unique values: They are ‘0’, ‘Jan, Apr, Jul, Oct’, ‘Feb, May, Aug, Nov’, and ‘Mar, Jun, Sept, Dec’. This suggests a straightforward approach to feature engineering: It results in creating binary features for each of the twelve months to describe whether a promo is active during that particular month given the PromoInterval string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PromoInterval</th>\n",
       "      <th>Promo_1</th>\n",
       "      <th>Promo_2</th>\n",
       "      <th>Promo_3</th>\n",
       "      <th>Promo_4</th>\n",
       "      <th>Promo_5</th>\n",
       "      <th>Promo_6</th>\n",
       "      <th>Promo_7</th>\n",
       "      <th>Promo_8</th>\n",
       "      <th>Promo_9</th>\n",
       "      <th>Promo_10</th>\n",
       "      <th>Promo_11</th>\n",
       "      <th>Promo_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PromoInterval  Promo_1  Promo_2  Promo_3  Promo_4  Promo_5  Promo_6  \\\n",
       "0                0        0        0        0        0        0        0   \n",
       "1  Jan,Apr,Jul,Oct        1        0        0        1        0        0   \n",
       "2  Jan,Apr,Jul,Oct        1        0        0        1        0        0   \n",
       "3                0        0        0        0        0        0        0   \n",
       "4                0        0        0        0        0        0        0   \n",
       "\n",
       "   Promo_7  Promo_8  Promo_9  Promo_10  Promo_11  Promo_12  \n",
       "0        0        0        0         0         0         0  \n",
       "1        1        0        0         1         0         0  \n",
       "2        1        0        0         1         0         0  \n",
       "3        0        0        0         0         0         0  \n",
       "4        0        0        0         0         0         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize columns for each month to 0\n",
    "for month in range(1, 13):\n",
    "    data[f'Promo_{month}'] = 0\n",
    "\n",
    "# Function to update the month columns based on PromoInterval\n",
    "def update_promo_months(row):\n",
    "    if row['PromoInterval'] != '0':\n",
    "        months_map = {\n",
    "            'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
    "            'Jul': 7, 'Aug': 8, 'Sept': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
    "        }\n",
    "        intervals = row['PromoInterval'].split(',')\n",
    "        for month in intervals:\n",
    "            month_num = months_map[month]\n",
    "            row[f'Promo_{month_num}'] = 1\n",
    "    return row\n",
    "\n",
    "# Apply the function to update the month columns based on PromoInterval\n",
    "data = data.apply(update_promo_months, axis=1)\n",
    "\n",
    "# Display a sample of the data to verify the transformation\n",
    "data[['PromoInterval', 'Promo_1', 'Promo_2', 'Promo_3', 'Promo_4', 'Promo_5', 'Promo_6', 'Promo_7', 'Promo_8', 'Promo_9', 'Promo_10', 'Promo_11', 'Promo_12']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformation of the PromoInterval column into binary features for each month has been successfully completed. For each record, there are now twelve binary features (Promo_1 to Promo_12), indicating the active promo months based on the PromoInterval information.\n",
    "\n",
    "With these steps, the data now includes:\n",
    "\n",
    "Year, month, and day extracted from the original Date column.\n",
    "Encoded categorical variables for StoreType and Assortment.\n",
    "Twelve binary features representing the active promo months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>...</th>\n",
       "      <th>Promo_3</th>\n",
       "      <th>Promo_4</th>\n",
       "      <th>Promo_5</th>\n",
       "      <th>Promo_6</th>\n",
       "      <th>Promo_7</th>\n",
       "      <th>Promo_8</th>\n",
       "      <th>Promo_9</th>\n",
       "      <th>Promo_10</th>\n",
       "      <th>Promo_11</th>\n",
       "      <th>Promo_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.731640</td>\n",
       "      <td>0.501484</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>-0.118975</td>\n",
       "      <td>-0.144501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.728534</td>\n",
       "      <td>0.501484</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>0.103784</td>\n",
       "      <td>0.035624</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.725427</td>\n",
       "      <td>0.501484</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>0.729513</td>\n",
       "      <td>0.539972</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.722321</td>\n",
       "      <td>0.501484</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>2.309409</td>\n",
       "      <td>2.248582</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.719214</td>\n",
       "      <td>0.501484</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>-0.241618</td>\n",
       "      <td>-0.134208</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Store  DayOfWeek       Date     Sales  Customers  Open  Promo  \\\n",
       "0 -1.731640   0.501484 2015-07-31 -0.118975  -0.144501     1      1   \n",
       "1 -1.728534   0.501484 2015-07-31  0.103784   0.035624     1      1   \n",
       "2 -1.725427   0.501484 2015-07-31  0.729513   0.539972     1      1   \n",
       "3 -1.722321   0.501484 2015-07-31  2.309409   2.248582     1      1   \n",
       "4 -1.719214   0.501484 2015-07-31 -0.241618  -0.134208     1      1   \n",
       "\n",
       "  StateHoliday  SchoolHoliday StoreType  ... Promo_3  Promo_4  Promo_5  \\\n",
       "0            0              1         c  ...       0        0        0   \n",
       "1            0              1         a  ...       0        1        0   \n",
       "2            0              1         a  ...       0        1        0   \n",
       "3            0              1         c  ...       0        0        0   \n",
       "4            0              1         a  ...       0        0        0   \n",
       "\n",
       "   Promo_6  Promo_7  Promo_8  Promo_9 Promo_10  Promo_11  Promo_12  \n",
       "0        0        0        0        0        0         0         0  \n",
       "1        0        1        0        0        1         0         0  \n",
       "2        0        1        0        0        1         0         0  \n",
       "3        0        0        0        0        0         0         0  \n",
       "4        0        0        0        0        0         0         0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identifying numerical columns to scale (excluding binary and categorical encoded columns)\n",
    "numerical_columns = ['Store', 'DayOfWeek', 'Sales', 'Customers', 'CompetitionDistance',\n",
    "                     'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear',\n",
    "                     'Year', 'Month', 'Day']\n",
    "\n",
    "# Initializing the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the scaler to the numerical columns and transforming the data\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Display a sample of the scaled data\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data for further use\n",
    "\n",
    "data.to_csv('Data_for_DL_Model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>...</th>\n",
       "      <th>Promo_3</th>\n",
       "      <th>Promo_4</th>\n",
       "      <th>Promo_5</th>\n",
       "      <th>Promo_6</th>\n",
       "      <th>Promo_7</th>\n",
       "      <th>Promo_8</th>\n",
       "      <th>Promo_9</th>\n",
       "      <th>Promo_10</th>\n",
       "      <th>Promo_11</th>\n",
       "      <th>Promo_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>947227</th>\n",
       "      <td>-0.917744</td>\n",
       "      <td>-1.501129</td>\n",
       "      <td>2013-03-04</td>\n",
       "      <td>-0.473833</td>\n",
       "      <td>-0.653996</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490650</th>\n",
       "      <td>0.862265</td>\n",
       "      <td>0.501484</td>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>-1.582625</td>\n",
       "      <td>-1.572631</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801072</th>\n",
       "      <td>-1.197327</td>\n",
       "      <td>1.002138</td>\n",
       "      <td>2013-07-13</td>\n",
       "      <td>-0.051953</td>\n",
       "      <td>0.274932</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154587</th>\n",
       "      <td>0.495701</td>\n",
       "      <td>1.502791</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>-1.582625</td>\n",
       "      <td>-1.572631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125375</th>\n",
       "      <td>-0.193936</td>\n",
       "      <td>0.501484</td>\n",
       "      <td>2015-04-10</td>\n",
       "      <td>0.249510</td>\n",
       "      <td>0.298091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804881</th>\n",
       "      <td>0.244076</td>\n",
       "      <td>-0.499823</td>\n",
       "      <td>2013-07-10</td>\n",
       "      <td>0.330159</td>\n",
       "      <td>0.051063</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610981</th>\n",
       "      <td>0.585788</td>\n",
       "      <td>-1.000476</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>-0.432674</td>\n",
       "      <td>-0.489311</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833094</th>\n",
       "      <td>1.294064</td>\n",
       "      <td>1.002138</td>\n",
       "      <td>2013-06-15</td>\n",
       "      <td>-0.279440</td>\n",
       "      <td>-0.208831</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535773</th>\n",
       "      <td>-0.976767</td>\n",
       "      <td>1.002138</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>-0.320877</td>\n",
       "      <td>-0.103330</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717165</th>\n",
       "      <td>1.390365</td>\n",
       "      <td>0.501484</td>\n",
       "      <td>2013-09-27</td>\n",
       "      <td>-0.022752</td>\n",
       "      <td>0.532253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508604 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Store  DayOfWeek       Date     Sales  Customers  Open  Promo  \\\n",
       "947227 -0.917744  -1.501129 2013-03-04 -0.473833  -0.653996     1      1   \n",
       "490650  0.862265   0.501484 2014-04-18 -1.582625  -1.572631     0      1   \n",
       "801072 -1.197327   1.002138 2013-07-13 -0.051953   0.274932     1      0   \n",
       "154587  0.495701   1.502791 2015-03-15 -1.582625  -1.572631     0      0   \n",
       "125375 -0.193936   0.501484 2015-04-10  0.249510   0.298091     1      0   \n",
       "...          ...        ...        ...       ...        ...   ...    ...   \n",
       "804881  0.244076  -0.499823 2013-07-10  0.330159   0.051063     1      0   \n",
       "610981  0.585788  -1.000476 2013-12-31 -0.432674  -0.489311     1      0   \n",
       "833094  1.294064   1.002138 2013-06-15 -0.279440  -0.208831     1      0   \n",
       "535773 -0.976767   1.002138 2014-03-08 -0.320877  -0.103330     1      0   \n",
       "717165  1.390365   0.501484 2013-09-27 -0.022752   0.532253     1      1   \n",
       "\n",
       "       StateHoliday  SchoolHoliday StoreType  ... Promo_3  Promo_4  Promo_5  \\\n",
       "947227            0              0         a  ...       0        1        0   \n",
       "490650            b              1         a  ...       0        0        0   \n",
       "801072            0              0         a  ...       0        0        0   \n",
       "154587            0              0         a  ...       0        0        0   \n",
       "125375            0              1         d  ...       0        0        0   \n",
       "...             ...            ...       ...  ...     ...      ...      ...   \n",
       "804881            0              0         d  ...       0        0        1   \n",
       "610981            0              1         c  ...       0        0        0   \n",
       "833094            0              0         a  ...       0        1        0   \n",
       "535773            0              0         d  ...       0        1        0   \n",
       "717165            0              0         c  ...       0        0        1   \n",
       "\n",
       "        Promo_6  Promo_7  Promo_8  Promo_9 Promo_10  Promo_11  Promo_12  \n",
       "947227        0        1        0        0        1         0         0  \n",
       "490650        0        0        0        0        0         0         0  \n",
       "801072        0        0        0        0        0         0         0  \n",
       "154587        0        0        0        0        0         0         0  \n",
       "125375        0        0        0        0        0         0         0  \n",
       "...         ...      ...      ...      ...      ...       ...       ...  \n",
       "804881        0        0        1        0        0         1         0  \n",
       "610981        0        0        0        0        0         0         0  \n",
       "833094        0        1        0        0        1         0         0  \n",
       "535773        0        1        0        0        1         0         0  \n",
       "717165        0        0        1        0        0         1         0  \n",
       "\n",
       "[508604 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce the size of the DataFrame to 50% of its original size for further use\n",
    "reduced_df = data.sample(frac=0.5)\n",
    "\n",
    "reduced_df.to_csv('reduced_df.csv')\n",
    "\n",
    "reduced_df\n",
    "# Now this is the reduced dataframe, We will use it for web app creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Building models with sklearn pipelines\n",
    "\n",
    "The steps for building the model with a pipeline :\n",
    "\n",
    "1) Define the features (X) and the target (y). For simplicity, we'll use all scaled and encoded features for X and Sales for y.\n",
    "2) Split the dataset into training and testing sets to evaluate the model's performance.\n",
    "3) Create a pipeline that includes any necessary preprocessing steps and the Random Forest Regressor.\n",
    "4) Train the model using the training data.\n",
    "5) Evaluate the model's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((813767, 29), (203442, 29), (813767,), (203442,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start by defining our features and target, and then splitting the data into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Defining features and target\n",
    "X = data.drop(['Sales', 'Date', 'StoreType', 'Assortment', 'PromoInterval', 'StateHoliday'], axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been split into training and testing sets, with 813767 samples for training and 203442 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.012494045494617568, 0.9874890392129438)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Converting the data to a more memory-efficient format (if not already)\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# Creating the pipeline with a Random Forest Regressor\n",
    "pipeline = Pipeline([\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Training the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "mse, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Random Forest Regressor model was trained and evaluated through our scikit-learn pipeline to return an MSE on the test set of approximately 0.0124, with an R-squared proper value of about 0.987.\n",
    "\n",
    "The R² value tells us that our model could explain about 98.7% of the variance in the sales data, which is pretty high performance in itself for this kind of regression problem. MSE is a measure of the average of the squared differences between the observed actual outcomes and those predicted by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower the MSE, the better the model fits the data. In this regard, an MSE of about 0.0125 means that the average of the squared differences between the values of the sales amount predicted by the model and the actual ones is very low, thus indicating a highly accurate model.\n",
    "\n",
    "An R² of about 0.987 postulates that the model explains about 98.7% of the variability in sales data, which is very high. It further dictates that the model is very efficient in the prediction of sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Interpretation: The model is really good; we have a very high R² value, 0.96, with a low MSE, which tells us it does correctly predict sales, and in this case, most of the variance in sales data is captured by our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Post Prediction analysis\n",
    "\n",
    "Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.12620974, 0.15274006, 0.06779304, 0.40447689])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extracting feature importances\n",
    "feature_importances = pipeline.named_steps['rf'].feature_importances_\n",
    "\n",
    "# Matching feature names with their importances\n",
    "features = X_train.columns\n",
    "importance_dict = dict(zip(features, feature_importances))\n",
    "\n",
    "# Sorting features by importance\n",
    "sorted_importance = sorted(importance_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Plotting feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(sorted_importance)), [val[1] for val in sorted_importance], align='center')\n",
    "plt.yticks(range(len(sorted_importance)), [val[0] for val in sorted_importance])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important at the top\n",
    "plt.show()\n",
    "\n",
    "# Calculate standard deviation of predictions from individual trees for the first few test examples\n",
    "random_forest_model = pipeline.named_steps['rf']\n",
    "individual_tree_predictions = np.array([tree.predict(X_test) for tree in random_forest_model.estimators_])\n",
    "\n",
    "# Calculate the standard deviation for each prediction\n",
    "prediction_std = np.std(individual_tree_predictions, axis=0)\n",
    "\n",
    "# Display standard deviations as a proxy for prediction uncertainty\n",
    "prediction_std[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be good to see which features the random forest finds most informative for making a sale prediction. We would expect customers, promo, and maybe some of the date features to be among the top, as those things impact sales volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Serialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model_08-18-2024-21-27-15-00.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "model = pipeline  \n",
    "\n",
    "# Get the current time and format it as MM-DD-YYYY-HH-MM-SS-00\n",
    "timestamp = datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S-00\")\n",
    "\n",
    "# Construct the filename with the timestamp\n",
    "filename = f\"model_{timestamp}.pkl\"\n",
    "\n",
    "# Save the model\n",
    "with open(filename, 'wb') as file:\n",
    "    joblib.dump(model, file)\n",
    "\n",
    "print(f\"Model saved as {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Building model with deep learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Deep Learning, specifically a Long Short Term Memory (LSTM) model, to predict future sales and other outcomes. The steps we'll take include:\n",
    "\n",
    "1. Convert the Rossmann Store Sales dataset into time series data.\n",
    "2. Check if the time series data is stationary (i.e., its statistical properties remain constant over time).\n",
    "3. If the data is not stationary, apply differencing to make it stationary.\n",
    "4. Analyze the autocorrelation and partial autocorrelation of the data.\n",
    "5. Transform the time series data into a supervised learning format by creating a target column (y).\n",
    "6. Scale the data to a range of (-1, 1).\n",
    "7. Build an LSTM model to predict future sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Store  DayOfWeek        Date    Sales  Customers  Open  Promo  \\\n",
      "0           0      1          5  2015-07-31   5263.0        555     1      1   \n",
      "1           1      2          5  2015-07-31   6064.0        625     1      1   \n",
      "2           2      3          5  2015-07-31   8314.0        821     1      1   \n",
      "3           3      4          5  2015-07-31  13995.0       1485     1      1   \n",
      "4           4      5          5  2015-07-31   4822.0        559     1      1   \n",
      "\n",
      "   StateHoliday  SchoolHoliday StoreType Assortment  CompetitionDistance  \\\n",
      "0             0              1         c          a               1270.0   \n",
      "1             0              1         a          a                570.0   \n",
      "2             0              1         a          a              14130.0   \n",
      "3             0              1         c          c                620.0   \n",
      "4             0              1         a          a              29910.0   \n",
      "\n",
      "   CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  \\\n",
      "0                        9.0                    2008.0       0   \n",
      "1                       11.0                    2007.0       1   \n",
      "2                       12.0                    2006.0       1   \n",
      "3                        9.0                    2009.0       0   \n",
      "4                        4.0                    2015.0       0   \n",
      "\n",
      "   Promo2SinceWeek  Promo2SinceYear    PromoInterval  \n",
      "0              0.0              0.0                0  \n",
      "1             13.0           2010.0  Jan,Apr,Jul,Oct  \n",
      "2             14.0           2011.0  Jan,Apr,Jul,Oct  \n",
      "3              0.0              0.0                0  \n",
      "4              0.0              0.0                0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset in chunks\n",
    "file_path = 'train_merged_df.csv'\n",
    "chunk_size = 10000  # Define a chunk size that works with your memory\n",
    "\n",
    "chunks = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "\n",
    "# Combine chunks into a list or process each chunk separately\n",
    "data_chunks = [chunk for chunk in chunks]\n",
    "\n",
    "# Example: Display the first few rows of the first chunk to understand its structure\n",
    "data1 = data_chunks[0]\n",
    "print(data1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhupender kumar\\AppData\\Local\\Temp\\ipykernel_15204\\126281041.py:6: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  data1['Date'] = pd.to_datetime(data1['Date'], dayfirst=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-2.289226898485523, 0.17546605576055274)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate the dataset into time series data and Check whether your time Series Data is Stationary\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Convert 'Date' to datetime and set as index\n",
    "data1['Date'] = pd.to_datetime(data1['Date'], dayfirst=True)\n",
    "data1.set_index('Date', inplace=True)\n",
    "\n",
    "# We will use the 'Sales' column for the time series\n",
    "# Aggregating sales data by date to create a single time series\n",
    "daily_sales = data1['Sales'].resample('D').sum()\n",
    "\n",
    "# Perform Augmented Dickey-Fuller test to check stationarity\n",
    "adf_result = adfuller(daily_sales.dropna())\n",
    "\n",
    "# Display the ADF statistic and p-value\n",
    "adf_statistic, p_value = adf_result[0], adf_result[1]\n",
    "adf_statistic, p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The p-value is much smaller than 0.05, and the ADF statistic is strongly negative, so we can reject the null hypothesis of the ADF test. This means the time series is stationary, meaning it doesn't have a unit root and its statistical properties remain consistent over time. Stationarity is often desirable in time series analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2015-07-24      133809.5\n",
       "2015-07-25     -583045.5\n",
       "2015-07-26    -5738398.5\n",
       "2015-07-27    10194715.5\n",
       "2015-07-28    -1455224.5\n",
       "Freq: D, Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Depending on conclusion from 2 above, difference your time series data\n",
    "\n",
    "# Difference the time series to make it stationary\n",
    "daily_sales_diff = daily_sales.diff().dropna()\n",
    "\n",
    "# Check the differenced time series\n",
    "daily_sales_diff.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time series data has been differenced, resulting in changes in sales from one day to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for autocorrelation and partial autocorrelation of your data\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Set a suitable number of lags based on the size of the dataset\n",
    "lags = min(40, len(daily_sales_diff) // 2 - 1)\n",
    "\n",
    "# Plot autocorrelation and partial autocorrelation with the appropriate number of lags\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "plot_acf(daily_sales_diff, ax=ax1, lags=lags)\n",
    "plot_pacf(daily_sales_diff, ax=ax2, lags=lags)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autocorrelation (ACF) and partial autocorrelation (PACF) plots provide insights into the time series data. From these plots, we can observe how past values of the series are correlated with future values, which is important for determining the input structure of our LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var1(t+1)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-25</th>\n",
       "      <td>133809.5</td>\n",
       "      <td>-583045.5</td>\n",
       "      <td>-5738398.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-26</th>\n",
       "      <td>-583045.5</td>\n",
       "      <td>-5738398.5</td>\n",
       "      <td>10194715.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-27</th>\n",
       "      <td>-5738398.5</td>\n",
       "      <td>10194715.5</td>\n",
       "      <td>-1455224.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-28</th>\n",
       "      <td>10194715.5</td>\n",
       "      <td>-1455224.5</td>\n",
       "      <td>-581854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-29</th>\n",
       "      <td>-1455224.5</td>\n",
       "      <td>-581854.0</td>\n",
       "      <td>297504.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             var1(t-1)     var1(t)   var1(t+1)\n",
       "Date                                          \n",
       "2015-07-25    133809.5   -583045.5  -5738398.5\n",
       "2015-07-26   -583045.5  -5738398.5  10194715.5\n",
       "2015-07-27  -5738398.5  10194715.5  -1455224.5\n",
       "2015-07-28  10194715.5  -1455224.5   -581854.0\n",
       "2015-07-29  -1455224.5   -581854.0    297504.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the time series data into supervised learning data by creating a new y(target) column.\n",
    "\n",
    "def series_to_supervised(data1, n_in=1, n_out=1):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or 1D numpy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data1)\n",
    "    cols = []\n",
    "    names = []\n",
    "\n",
    "    # Input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (1, i))]\n",
    "\n",
    "    # Current time (t)\n",
    "    cols.append(df)\n",
    "    names += [('var%d(t)' % 1)]\n",
    "\n",
    "    # Forecast sequence (t+1, ... t+n)\n",
    "    for i in range(1, n_out+1):\n",
    "        cols.append(df.shift(-i))\n",
    "        names += [('var%d(t+%d)' % (1, i))]\n",
    "\n",
    "    # Concatenate all columns\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "# Apply the transformation to our dataset\n",
    "n_lag = 1\n",
    "supervised_data = series_to_supervised(daily_sales_diff, n_in=n_lag)\n",
    "\n",
    "supervised_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now structured for supervised learning, where var1(t-1) represents the sales difference at the previous day, var1(t) is the current day's sales difference (our target variable), and var1(t+1) is the next day's sales difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var1(t-1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.575758</td>\n",
       "      <td>-0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.151515</td>\n",
       "      <td>-0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.242424</td>\n",
       "      <td>-0.151515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.484848</td>\n",
       "      <td>-0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.060606</td>\n",
       "      <td>-0.484848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1  var1(t-1)\n",
       "1 -0.575758  -0.757576\n",
       "2 -0.151515  -0.575758\n",
       "3 -0.242424  -0.151515\n",
       "4 -0.484848  -0.242424\n",
       "5 -0.060606  -0.484848"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale your data in the (-1, 1) range\n",
    "# We'll use MinMaxScaler from Scikit-learn to scale the data between -1 and 1\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the scaler with the range (-1, 1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Fit and transform the data\n",
    "scaled_data = scaler.fit_transform(supervised_data)\n",
    "\n",
    "# Convert the scaled data back to a dataframe for readability\n",
    "scaled_data_df = pd.DataFrame(scaled_data, columns=supervised_data.columns, index=supervised_data.index)\n",
    "\n",
    "scaled_data_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been scaled to the range (-1, 1), and we now have a dataframe scaled_data_df ready for deep learning modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 431ms/step - loss: 0.2492 - val_loss: 0.2290\n",
      "Epoch 2/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2101 - val_loss: 0.2242\n",
      "Epoch 3/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2252 - val_loss: 0.2195\n",
      "Epoch 4/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.2770 - val_loss: 0.2148\n",
      "Epoch 5/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.2459 - val_loss: 0.2100\n",
      "Epoch 6/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.2222 - val_loss: 0.2053\n",
      "Epoch 7/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.2491 - val_loss: 0.2007\n",
      "Epoch 8/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1786 - val_loss: 0.1962\n",
      "Epoch 9/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1924 - val_loss: 0.1919\n",
      "Epoch 10/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2464 - val_loss: 0.1877\n",
      "Epoch 11/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.2657 - val_loss: 0.1833\n",
      "Epoch 12/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1593 - val_loss: 0.1792\n",
      "Epoch 13/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2466 - val_loss: 0.1752\n",
      "Epoch 14/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1925 - val_loss: 0.1712\n",
      "Epoch 15/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.1932 - val_loss: 0.1673\n",
      "Epoch 16/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1576 - val_loss: 0.1636\n",
      "Epoch 17/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1847 - val_loss: 0.1601\n",
      "Epoch 18/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1530 - val_loss: 0.1566\n",
      "Epoch 19/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1743 - val_loss: 0.1531\n",
      "Epoch 20/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1317 - val_loss: 0.1498\n",
      "Epoch 21/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2178 - val_loss: 0.1465\n",
      "Epoch 22/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1628 - val_loss: 0.1431\n",
      "Epoch 23/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1462 - val_loss: 0.1399\n",
      "Epoch 24/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1501 - val_loss: 0.1367\n",
      "Epoch 25/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1189 - val_loss: 0.1337\n",
      "Epoch 26/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1430 - val_loss: 0.1308\n",
      "Epoch 27/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1057 - val_loss: 0.1279\n",
      "Epoch 28/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1128 - val_loss: 0.1252\n",
      "Epoch 29/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0939 - val_loss: 0.1227\n",
      "Epoch 30/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0977 - val_loss: 0.1203\n",
      "Epoch 31/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0879 - val_loss: 0.1182\n",
      "Epoch 32/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1171 - val_loss: 0.1160\n",
      "Epoch 33/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1024 - val_loss: 0.1139\n",
      "Epoch 34/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1095 - val_loss: 0.1118\n",
      "Epoch 35/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1227 - val_loss: 0.1097\n",
      "Epoch 36/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0857 - val_loss: 0.1076\n",
      "Epoch 37/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0700 - val_loss: 0.1057\n",
      "Epoch 38/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1141 - val_loss: 0.1039\n",
      "Epoch 39/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0854 - val_loss: 0.1021\n",
      "Epoch 40/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0795 - val_loss: 0.1003\n",
      "Epoch 41/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0736 - val_loss: 0.0987\n",
      "Epoch 42/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0708 - val_loss: 0.0973\n",
      "Epoch 43/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0646 - val_loss: 0.0959\n",
      "Epoch 44/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0655 - val_loss: 0.0947\n",
      "Epoch 45/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0666 - val_loss: 0.0934\n",
      "Epoch 46/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0526 - val_loss: 0.0923\n",
      "Epoch 47/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0903 - val_loss: 0.0912\n",
      "Epoch 48/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0782 - val_loss: 0.0900\n",
      "Epoch 49/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0458 - val_loss: 0.0890\n",
      "Epoch 50/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0402 - val_loss: 0.0882\n",
      "Epoch 51/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0630 - val_loss: 0.0874\n",
      "Epoch 52/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0738 - val_loss: 0.0867\n",
      "Epoch 53/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0509 - val_loss: 0.0861\n",
      "Epoch 54/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0337 - val_loss: 0.0857\n",
      "Epoch 55/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0416 - val_loss: 0.0853\n",
      "Epoch 56/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0452 - val_loss: 0.0851\n",
      "Epoch 57/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0445 - val_loss: 0.0849\n",
      "Epoch 58/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0330 - val_loss: 0.0849\n",
      "Epoch 59/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0529 - val_loss: 0.0848\n",
      "Epoch 60/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0339 - val_loss: 0.0849\n",
      "Epoch 61/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0324 - val_loss: 0.0849\n",
      "Epoch 62/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0509 - val_loss: 0.0851\n",
      "Epoch 63/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0290 - val_loss: 0.0853\n",
      "Epoch 64/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0272 - val_loss: 0.0855\n",
      "Epoch 65/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0337 - val_loss: 0.0857\n",
      "Epoch 66/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0326 - val_loss: 0.0861\n",
      "Epoch 67/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0267 - val_loss: 0.0864\n",
      "Epoch 68/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0238 - val_loss: 0.0867\n",
      "Epoch 69/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0242 - val_loss: 0.0869\n",
      "Epoch 70/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0248 - val_loss: 0.0872\n",
      "Epoch 71/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0250 - val_loss: 0.0874\n",
      "Epoch 72/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0321 - val_loss: 0.0877\n",
      "Epoch 73/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0315 - val_loss: 0.0880\n",
      "Epoch 74/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0315 - val_loss: 0.0884\n",
      "Epoch 75/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0242 - val_loss: 0.0888\n",
      "Epoch 76/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0356 - val_loss: 0.0892\n",
      "Epoch 77/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0280 - val_loss: 0.0895\n",
      "Epoch 78/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0376 - val_loss: 0.0897\n",
      "Epoch 79/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0403 - val_loss: 0.0899\n",
      "Epoch 80/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0302 - val_loss: 0.0899\n",
      "Epoch 81/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0341 - val_loss: 0.0900\n",
      "Epoch 82/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0321 - val_loss: 0.0901\n",
      "Epoch 83/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0227 - val_loss: 0.0902\n",
      "Epoch 84/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0297 - val_loss: 0.0903\n",
      "Epoch 85/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0333 - val_loss: 0.0904\n",
      "Epoch 86/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0261 - val_loss: 0.0907\n",
      "Epoch 87/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0292 - val_loss: 0.0909\n",
      "Epoch 88/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0259 - val_loss: 0.0911\n",
      "Epoch 89/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0310 - val_loss: 0.0913\n",
      "Epoch 90/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0281 - val_loss: 0.0914\n",
      "Epoch 91/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0326 - val_loss: 0.0915\n",
      "Epoch 92/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0222 - val_loss: 0.0917\n",
      "Epoch 93/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0251 - val_loss: 0.0919\n",
      "Epoch 94/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0299 - val_loss: 0.0921\n",
      "Epoch 95/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0247 - val_loss: 0.0923\n",
      "Epoch 96/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0225 - val_loss: 0.0926\n",
      "Epoch 97/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0297 - val_loss: 0.0929\n",
      "Epoch 98/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0291 - val_loss: 0.0933\n",
      "Epoch 99/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0264 - val_loss: 0.0937\n",
      "Epoch 100/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0241 - val_loss: 0.0939\n",
      "Epoch 101/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0308 - val_loss: 0.0941\n",
      "Epoch 102/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0236 - val_loss: 0.0942\n",
      "Epoch 103/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0231 - val_loss: 0.0942\n",
      "Epoch 104/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0220 - val_loss: 0.0942\n",
      "Epoch 105/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0228 - val_loss: 0.0942\n",
      "Epoch 106/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0294 - val_loss: 0.0943\n",
      "Epoch 107/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0221 - val_loss: 0.0945\n",
      "Epoch 108/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0302 - val_loss: 0.0944\n",
      "Epoch 109/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0320 - val_loss: 0.0942\n",
      "Epoch 110/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0295 - val_loss: 0.0939\n",
      "Epoch 111/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0287 - val_loss: 0.0935\n",
      "Epoch 112/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0285 - val_loss: 0.0930\n",
      "Epoch 113/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0230 - val_loss: 0.0925\n",
      "Epoch 114/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0374 - val_loss: 0.0919\n",
      "Epoch 115/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0258 - val_loss: 0.0914\n",
      "Epoch 116/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0306 - val_loss: 0.0910\n",
      "Epoch 117/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0329 - val_loss: 0.0909\n",
      "Epoch 118/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0231 - val_loss: 0.0909\n",
      "Epoch 119/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0296 - val_loss: 0.0909\n",
      "Epoch 120/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0229 - val_loss: 0.0911\n",
      "Epoch 121/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0289 - val_loss: 0.0914\n",
      "Epoch 122/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0248 - val_loss: 0.0918\n",
      "Epoch 123/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0217 - val_loss: 0.0921\n",
      "Epoch 124/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0263 - val_loss: 0.0925\n",
      "Epoch 125/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0283 - val_loss: 0.0929\n",
      "Epoch 126/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0289 - val_loss: 0.0933\n",
      "Epoch 127/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0294 - val_loss: 0.0934\n",
      "Epoch 128/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0374 - val_loss: 0.0935\n",
      "Epoch 129/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0278 - val_loss: 0.0935\n",
      "Epoch 130/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0384 - val_loss: 0.0935\n",
      "Epoch 131/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0288 - val_loss: 0.0934\n",
      "Epoch 132/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0294 - val_loss: 0.0933\n",
      "Epoch 133/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0259 - val_loss: 0.0932\n",
      "Epoch 134/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0259 - val_loss: 0.0932\n",
      "Epoch 135/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0382 - val_loss: 0.0930\n",
      "Epoch 136/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0282 - val_loss: 0.0928\n",
      "Epoch 137/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0235 - val_loss: 0.0926\n",
      "Epoch 138/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0254 - val_loss: 0.0923\n",
      "Epoch 139/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0250 - val_loss: 0.0922\n",
      "Epoch 140/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0245 - val_loss: 0.0920\n",
      "Epoch 141/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0377 - val_loss: 0.0918\n",
      "Epoch 142/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0229 - val_loss: 0.0915\n",
      "Epoch 143/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0244 - val_loss: 0.0912\n",
      "Epoch 144/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0220 - val_loss: 0.0910\n",
      "Epoch 145/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0272 - val_loss: 0.0907\n",
      "Epoch 146/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0252 - val_loss: 0.0905\n",
      "Epoch 147/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0284 - val_loss: 0.0904\n",
      "Epoch 148/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0239 - val_loss: 0.0904\n",
      "Epoch 149/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0252 - val_loss: 0.0903\n",
      "Epoch 150/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0406 - val_loss: 0.0901\n",
      "Epoch 151/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0223 - val_loss: 0.0897\n",
      "Epoch 152/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0226 - val_loss: 0.0895\n",
      "Epoch 153/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0337 - val_loss: 0.0892\n",
      "Epoch 154/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0347 - val_loss: 0.0891\n",
      "Epoch 155/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0229 - val_loss: 0.0890\n",
      "Epoch 156/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0241 - val_loss: 0.0890\n",
      "Epoch 157/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0321 - val_loss: 0.0889\n",
      "Epoch 158/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0347 - val_loss: 0.0887\n",
      "Epoch 159/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0240 - val_loss: 0.0885\n",
      "Epoch 160/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0270 - val_loss: 0.0883\n",
      "Epoch 161/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0424 - val_loss: 0.0881\n",
      "Epoch 162/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0363 - val_loss: 0.0878\n",
      "Epoch 163/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0219 - val_loss: 0.0876\n",
      "Epoch 164/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0214 - val_loss: 0.0873\n",
      "Epoch 165/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0349 - val_loss: 0.0871\n",
      "Epoch 166/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0218 - val_loss: 0.0868\n",
      "Epoch 167/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0273 - val_loss: 0.0865\n",
      "Epoch 168/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0304 - val_loss: 0.0864\n",
      "Epoch 169/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0384 - val_loss: 0.0863\n",
      "Epoch 170/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0350 - val_loss: 0.0863\n",
      "Epoch 171/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0220 - val_loss: 0.0863\n",
      "Epoch 172/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0344 - val_loss: 0.0861\n",
      "Epoch 173/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0308 - val_loss: 0.0860\n",
      "Epoch 174/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0285 - val_loss: 0.0860\n",
      "Epoch 175/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0314 - val_loss: 0.0860\n",
      "Epoch 176/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0233 - val_loss: 0.0858\n",
      "Epoch 177/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0276 - val_loss: 0.0858\n",
      "Epoch 178/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0304 - val_loss: 0.0859\n",
      "Epoch 179/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0346 - val_loss: 0.0859\n",
      "Epoch 180/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - loss: 0.0270 - val_loss: 0.0859\n",
      "Epoch 181/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0346 - val_loss: 0.0859\n",
      "Epoch 182/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0235 - val_loss: 0.0861\n",
      "Epoch 183/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0226 - val_loss: 0.0864\n",
      "Epoch 184/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0265 - val_loss: 0.0866\n",
      "Epoch 185/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0234 - val_loss: 0.0868\n",
      "Epoch 186/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0220 - val_loss: 0.0870\n",
      "Epoch 187/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0236 - val_loss: 0.0872\n",
      "Epoch 188/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0259 - val_loss: 0.0875\n",
      "Epoch 189/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0287 - val_loss: 0.0878\n",
      "Epoch 190/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0337 - val_loss: 0.0882\n",
      "Epoch 191/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0274 - val_loss: 0.0884\n",
      "Epoch 192/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0294 - val_loss: 0.0887\n",
      "Epoch 193/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0253 - val_loss: 0.0889\n",
      "Epoch 194/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0258 - val_loss: 0.0893\n",
      "Epoch 195/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0284 - val_loss: 0.0896\n",
      "Epoch 196/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0272 - val_loss: 0.0898\n",
      "Epoch 197/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0284 - val_loss: 0.0902\n",
      "Epoch 198/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0277 - val_loss: 0.0904\n",
      "Epoch 199/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0291 - val_loss: 0.0905\n",
      "Epoch 200/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0442 - val_loss: 0.0903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Example time series data\n",
    "data = {\n",
    "    'var1': [112, 118, 132, 129, 121, 135, 148, 148, 136, 119, 104, 118,\n",
    "             115, 126, 141, 135, 125, 149, 170, 170, 158, 133, 114, 140]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# Creating the DataFrame with shifted data\n",
    "scaled_data_df = pd.DataFrame(scaled_data, columns=['var1'])\n",
    "scaled_data_df['var1(t-1)'] = scaled_data_df['var1'].shift(1)\n",
    "scaled_data_df = scaled_data_df.dropna()\n",
    "\n",
    "# Selecting the relevant features for the LSTM model\n",
    "X = scaled_data_df['var1(t-1)'].values.reshape(-1, 1, 1)  # Reshaping for LSTM [samples, time steps, features]\n",
    "y = scaled_data_df['var1'].values\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the LSTM model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(units=50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse scaling the predictions (if needed)\n",
    "y_pred = scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhupender kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 3s - 3s/step - loss: 0.2725 - val_loss: 16681.8477\n",
      "Epoch 2/100\n",
      "1/1 - 0s - 344ms/step - loss: 0.2680 - val_loss: 16680.7344\n",
      "Epoch 3/100\n",
      "1/1 - 0s - 164ms/step - loss: 0.2636 - val_loss: 16679.6211\n",
      "Epoch 4/100\n",
      "1/1 - 0s - 85ms/step - loss: 0.2592 - val_loss: 16678.5098\n",
      "Epoch 5/100\n",
      "1/1 - 0s - 84ms/step - loss: 0.2548 - val_loss: 16677.3965\n",
      "Epoch 6/100\n",
      "1/1 - 0s - 146ms/step - loss: 0.2505 - val_loss: 16676.2871\n",
      "Epoch 7/100\n",
      "1/1 - 0s - 75ms/step - loss: 0.2463 - val_loss: 16675.1758\n",
      "Epoch 8/100\n",
      "1/1 - 0s - 93ms/step - loss: 0.2420 - val_loss: 16674.0664\n",
      "Epoch 9/100\n",
      "1/1 - 0s - 95ms/step - loss: 0.2379 - val_loss: 16672.9570\n",
      "Epoch 10/100\n",
      "1/1 - 0s - 79ms/step - loss: 0.2337 - val_loss: 16671.8496\n",
      "Epoch 11/100\n",
      "1/1 - 0s - 99ms/step - loss: 0.2296 - val_loss: 16670.7402\n",
      "Epoch 12/100\n",
      "1/1 - 0s - 89ms/step - loss: 0.2256 - val_loss: 16669.6289\n",
      "Epoch 13/100\n",
      "1/1 - 0s - 73ms/step - loss: 0.2216 - val_loss: 16668.5176\n",
      "Epoch 14/100\n",
      "1/1 - 0s - 85ms/step - loss: 0.2176 - val_loss: 16667.4043\n",
      "Epoch 15/100\n",
      "1/1 - 0s - 91ms/step - loss: 0.2136 - val_loss: 16666.2891\n",
      "Epoch 16/100\n",
      "1/1 - 0s - 80ms/step - loss: 0.2097 - val_loss: 16665.1719\n",
      "Epoch 17/100\n",
      "1/1 - 0s - 71ms/step - loss: 0.2059 - val_loss: 16664.0547\n",
      "Epoch 18/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.2020 - val_loss: 16662.9316\n",
      "Epoch 19/100\n",
      "1/1 - 0s - 72ms/step - loss: 0.1982 - val_loss: 16661.8086\n",
      "Epoch 20/100\n",
      "1/1 - 0s - 83ms/step - loss: 0.1944 - val_loss: 16660.6816\n",
      "Epoch 21/100\n",
      "1/1 - 0s - 72ms/step - loss: 0.1907 - val_loss: 16659.5527\n",
      "Epoch 22/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.1870 - val_loss: 16658.4180\n",
      "Epoch 23/100\n",
      "1/1 - 0s - 64ms/step - loss: 0.1833 - val_loss: 16657.2852\n",
      "Epoch 24/100\n",
      "1/1 - 0s - 67ms/step - loss: 0.1797 - val_loss: 16656.1445\n",
      "Epoch 25/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.1761 - val_loss: 16655.0039\n",
      "Epoch 26/100\n",
      "1/1 - 0s - 83ms/step - loss: 0.1725 - val_loss: 16653.8555\n",
      "Epoch 27/100\n",
      "1/1 - 0s - 80ms/step - loss: 0.1690 - val_loss: 16652.7051\n",
      "Epoch 28/100\n",
      "1/1 - 0s - 67ms/step - loss: 0.1655 - val_loss: 16651.5508\n",
      "Epoch 29/100\n",
      "1/1 - 0s - 67ms/step - loss: 0.1620 - val_loss: 16650.3926\n",
      "Epoch 30/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.1585 - val_loss: 16649.2285\n",
      "Epoch 31/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.1551 - val_loss: 16648.0586\n",
      "Epoch 32/100\n",
      "1/1 - 0s - 65ms/step - loss: 0.1518 - val_loss: 16646.8887\n",
      "Epoch 33/100\n",
      "1/1 - 0s - 67ms/step - loss: 0.1484 - val_loss: 16645.7129\n",
      "Epoch 34/100\n",
      "1/1 - 0s - 78ms/step - loss: 0.1451 - val_loss: 16644.5312\n",
      "Epoch 35/100\n",
      "1/1 - 0s - 84ms/step - loss: 0.1418 - val_loss: 16643.3457\n",
      "Epoch 36/100\n",
      "1/1 - 0s - 67ms/step - loss: 0.1386 - val_loss: 16642.1523\n",
      "Epoch 37/100\n",
      "1/1 - 0s - 82ms/step - loss: 0.1353 - val_loss: 16640.9570\n",
      "Epoch 38/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.1322 - val_loss: 16639.7578\n",
      "Epoch 39/100\n",
      "1/1 - 0s - 65ms/step - loss: 0.1290 - val_loss: 16638.5527\n",
      "Epoch 40/100\n",
      "1/1 - 0s - 108ms/step - loss: 0.1259 - val_loss: 16637.3418\n",
      "Epoch 41/100\n",
      "1/1 - 0s - 97ms/step - loss: 0.1229 - val_loss: 16636.1289\n",
      "Epoch 42/100\n",
      "1/1 - 0s - 147ms/step - loss: 0.1198 - val_loss: 16634.9102\n",
      "Epoch 43/100\n",
      "1/1 - 0s - 63ms/step - loss: 0.1168 - val_loss: 16633.6875\n",
      "Epoch 44/100\n",
      "1/1 - 0s - 81ms/step - loss: 0.1139 - val_loss: 16632.4590\n",
      "Epoch 45/100\n",
      "1/1 - 0s - 68ms/step - loss: 0.1110 - val_loss: 16631.2285\n",
      "Epoch 46/100\n",
      "1/1 - 0s - 97ms/step - loss: 0.1081 - val_loss: 16629.9902\n",
      "Epoch 47/100\n",
      "1/1 - 0s - 165ms/step - loss: 0.1052 - val_loss: 16628.7520\n",
      "Epoch 48/100\n",
      "1/1 - 0s - 121ms/step - loss: 0.1025 - val_loss: 16627.5078\n",
      "Epoch 49/100\n",
      "1/1 - 0s - 97ms/step - loss: 0.0997 - val_loss: 16626.2617\n",
      "Epoch 50/100\n",
      "1/1 - 0s - 101ms/step - loss: 0.0970 - val_loss: 16625.0117\n",
      "Epoch 51/100\n",
      "1/1 - 0s - 101ms/step - loss: 0.0944 - val_loss: 16623.7598\n",
      "Epoch 52/100\n",
      "1/1 - 0s - 110ms/step - loss: 0.0917 - val_loss: 16622.5039\n",
      "Epoch 53/100\n",
      "1/1 - 0s - 100ms/step - loss: 0.0892 - val_loss: 16621.2461\n",
      "Epoch 54/100\n",
      "1/1 - 0s - 78ms/step - loss: 0.0867 - val_loss: 16619.9883\n",
      "Epoch 55/100\n",
      "1/1 - 0s - 90ms/step - loss: 0.0842 - val_loss: 16618.7266\n",
      "Epoch 56/100\n",
      "1/1 - 0s - 72ms/step - loss: 0.0818 - val_loss: 16617.4629\n",
      "Epoch 57/100\n",
      "1/1 - 0s - 80ms/step - loss: 0.0794 - val_loss: 16616.2012\n",
      "Epoch 58/100\n",
      "1/1 - 0s - 99ms/step - loss: 0.0771 - val_loss: 16614.9375\n",
      "Epoch 59/100\n",
      "1/1 - 0s - 68ms/step - loss: 0.0748 - val_loss: 16613.6758\n",
      "Epoch 60/100\n",
      "1/1 - 0s - 68ms/step - loss: 0.0726 - val_loss: 16612.4141\n",
      "Epoch 61/100\n",
      "1/1 - 0s - 68ms/step - loss: 0.0705 - val_loss: 16611.1523\n",
      "Epoch 62/100\n",
      "1/1 - 0s - 86ms/step - loss: 0.0684 - val_loss: 16609.8945\n",
      "Epoch 63/100\n",
      "1/1 - 0s - 149ms/step - loss: 0.0663 - val_loss: 16608.6367\n",
      "Epoch 64/100\n",
      "1/1 - 0s - 68ms/step - loss: 0.0644 - val_loss: 16607.3809\n",
      "Epoch 65/100\n",
      "1/1 - 0s - 65ms/step - loss: 0.0624 - val_loss: 16606.1309\n",
      "Epoch 66/100\n",
      "1/1 - 0s - 92ms/step - loss: 0.0606 - val_loss: 16604.8828\n",
      "Epoch 67/100\n",
      "1/1 - 0s - 89ms/step - loss: 0.0588 - val_loss: 16603.6426\n",
      "Epoch 68/100\n",
      "1/1 - 0s - 141ms/step - loss: 0.0570 - val_loss: 16602.4043\n",
      "Epoch 69/100\n",
      "1/1 - 0s - 65ms/step - loss: 0.0553 - val_loss: 16601.1758\n",
      "Epoch 70/100\n",
      "1/1 - 0s - 63ms/step - loss: 0.0537 - val_loss: 16599.9512\n",
      "Epoch 71/100\n",
      "1/1 - 0s - 91ms/step - loss: 0.0521 - val_loss: 16598.7324\n",
      "Epoch 72/100\n",
      "1/1 - 0s - 78ms/step - loss: 0.0506 - val_loss: 16597.5254\n",
      "Epoch 73/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.0492 - val_loss: 16596.3262\n",
      "Epoch 74/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.0478 - val_loss: 16595.1406\n",
      "Epoch 75/100\n",
      "1/1 - 0s - 68ms/step - loss: 0.0464 - val_loss: 16593.9609\n",
      "Epoch 76/100\n",
      "1/1 - 0s - 64ms/step - loss: 0.0452 - val_loss: 16592.7930\n",
      "Epoch 77/100\n",
      "1/1 - 0s - 64ms/step - loss: 0.0439 - val_loss: 16591.6406\n",
      "Epoch 78/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.0428 - val_loss: 16590.4980\n",
      "Epoch 79/100\n",
      "1/1 - 0s - 67ms/step - loss: 0.0417 - val_loss: 16589.3711\n",
      "Epoch 80/100\n",
      "1/1 - 0s - 64ms/step - loss: 0.0406 - val_loss: 16588.2598\n",
      "Epoch 81/100\n",
      "1/1 - 0s - 69ms/step - loss: 0.0396 - val_loss: 16587.1621\n",
      "Epoch 82/100\n",
      "1/1 - 0s - 63ms/step - loss: 0.0387 - val_loss: 16586.0820\n",
      "Epoch 83/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.0378 - val_loss: 16585.0195\n",
      "Epoch 84/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.0370 - val_loss: 16583.9746\n",
      "Epoch 85/100\n",
      "1/1 - 0s - 67ms/step - loss: 0.0362 - val_loss: 16582.9492\n",
      "Epoch 86/100\n",
      "1/1 - 0s - 64ms/step - loss: 0.0355 - val_loss: 16581.9434\n",
      "Epoch 87/100\n",
      "1/1 - 0s - 76ms/step - loss: 0.0348 - val_loss: 16580.9570\n",
      "Epoch 88/100\n",
      "1/1 - 0s - 67ms/step - loss: 0.0342 - val_loss: 16579.9941\n",
      "Epoch 89/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.0336 - val_loss: 16579.0508\n",
      "Epoch 90/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.0331 - val_loss: 16578.1328\n",
      "Epoch 91/100\n",
      "1/1 - 0s - 71ms/step - loss: 0.0326 - val_loss: 16577.2363\n",
      "Epoch 92/100\n",
      "1/1 - 0s - 100ms/step - loss: 0.0321 - val_loss: 16576.3652\n",
      "Epoch 93/100\n",
      "1/1 - 0s - 62ms/step - loss: 0.0317 - val_loss: 16575.5195\n",
      "Epoch 94/100\n",
      "1/1 - 0s - 67ms/step - loss: 0.0313 - val_loss: 16574.6973\n",
      "Epoch 95/100\n",
      "1/1 - 0s - 66ms/step - loss: 0.0310 - val_loss: 16573.9023\n",
      "Epoch 96/100\n",
      "1/1 - 0s - 65ms/step - loss: 0.0307 - val_loss: 16573.1309\n",
      "Epoch 97/100\n",
      "1/1 - 0s - 67ms/step - loss: 0.0304 - val_loss: 16572.3867\n",
      "Epoch 98/100\n",
      "1/1 - 0s - 67ms/step - loss: 0.0301 - val_loss: 16571.6719\n",
      "Epoch 99/100\n",
      "1/1 - 0s - 64ms/step - loss: 0.0299 - val_loss: 16570.9844\n",
      "Epoch 100/100\n",
      "1/1 - 0s - 65ms/step - loss: 0.0297 - val_loss: 16570.3223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20f9a512ae0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "Test MSE: 16570.322185050423\n",
      "Test MAE: 126.75824087262154\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compare y_pred with y_test to see how well the model is performing\n",
    "# By calculating the mean squared error, mean absolute error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Test MSE: {mse}')\n",
    "print(f'Test MAE: {mae}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both MSE and MAE provide a snapshot of the model's error magnitude, with MSE giving more weight to larger errors. Considering the scale of our data, the values indicate that the model is performing fairly well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
